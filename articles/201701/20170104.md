# DeepLearning(4): CNNの逆伝播完成？

また時間が経ってしまった。今回は畳み込み層の逆伝播のアルゴリズムを
理解するのに手間取ってしまった。。。気を取り直して、逆伝播の後半戦といこう。

## 1. 各層のおさらい

今回作っているプログラムは次のように11層のレイヤで画像を学習・評価している。

|No.|層|実装|
|:-:|:-|:-|
|0|入力|-|
|1|畳み込み層1|×|
|2|活性化層1|○|
|3|プーリング層1|×|
|4|畳み込み層2|×|
|5|活性化層2|○|
|6|プーリング層2|×|
|7|平坦化層|×|
|8|全結合層1|○|
|9|活性化層3|○|
|10|全結合層2|○|
|11|活性化層4(出力)|○|

前回までで全結合層の逆伝播処理は説明したので、それらの処理は実装済み、
残るは×のついている層だ。次節で、平準化層、プーリング層、畳み込み層に
ついて見ていこう。

その前に、前回のプログラムでは逆伝播において伝播させる誤差($\delta$)を
次のように`Double`の一次元配列(というかリスト)とした。

```haskell
type Delta = [Double]
```

しかしプーリング層や畳み込み層では、誤差は単純な一次元配列にならず、画像と
同じくXY画面がNチャネルという三次元のデータになる。ということで、次のように
改めた。なのですでに実装済みとした部分もこれに合わせて変更してある。

```haskell
type Delta = Image  -- (= [[[Double]]])
```

## 2. 各層の逆伝播処理

### 2-1. 平坦化(Flatten)層

前回は全結合層までの実装だったので、上記の表で言えば No.11 → No.8 までしか
できていなかった。平坦化層はCNNの醍醐味である畳み込み層へ誤差を伝えるための
重要な転換点だ。が、実装は極めて単純だった。

```haskell:FlattenLayer.hs
unflatten :: Int -> Int -> Image -> Image
unflatten x y [[ds]] = split y $ split x ds
  where
    split :: Int -> [a] -> [[a]]
    split _ [] = []
    split n ds = d : split n ds'
      where
        (d, ds') = splitAt n ds
```

この層の逆伝播(`unflatten`)処理は、下層から一次元配列で伝わってきた誤差を
画像形式(=三次元配列)に組み替えて上層に伝えること。順伝播では画像形式を
一列に並び替えたのでその逆だ。画像一枚の画素数(X,Y)は引数で与える。
第三引数が微妙な形(`[[ds]]`)になっているのは`Delta`型を変更したから。
`ds`の型は`[Double]`だ。

ちなみに、入力されるデータ数がX,Y画素できちんと割り切れることを想定して
いて何のエラー処理もしていない。。。

### 2-2. プーリング層

プーリング層にはフィルタ情報がないので、下層から伝播してきた誤差($\Delta$)を
更新して上層を伝えれば良い。ただ、プーリング層の更新処理は特殊だ。
他の層では誤差に何らかの計算処理をすればよいが、プーリング層では次のような
ことをしないといけない。

* 順伝播の際に小領域(2x2とか3x3とか)から最大値を選択し、その画素の位置を
  覚えておく。
* 逆伝播時は、誤差をその選択した位置に置き、小領域のそれ以外の画素には
  0を設定する。

これを図にしたらこんな感じ。

（図）


前回までのプログラムでは、順伝播でのプーリング層への入力画像は記録して
いるものの、どの画素を選択したかという情報は記録していなかった。
[yusugomori実装]()では、選択画素を記録しておく代わりにプーリング層の
出力値=選択された画素の値を使って、小領域の値と順次比較することで
どの画素を選択したかを特定するようになっている。
つまり誤差を求めるために「プーリング層の入力値と出力値の両方を使っている」
のだ。

しかし私の実装では、逆伝播を再帰で綺麗に(?)処理しようとしているために
誤差の計算は「各層の入力値のみ使う」形にしている。このシンプルな構造は
維持したい・・・。

最終結論は「プーリング層の入力値を改竄する」だった(笑)。そのために
順伝播での処理をこう変えた。

* 画像を小領域に分割する(`poolMaxLine`)
* 小領域の各画素に番号を付ける(`zip`で画素値と追番を組(`Pix`)にする)
* 小領域中の画素の最大値を選択する(`max'`)
* 選択した情報を集めると、(最大値,小領域中の追番)の組の集合になる
* 組の第一要素は下層へ伝える出力値、第二要素は「最大値画素の小領域内の
  追番(の集合)」になる(`poolMax`)
* プーリング層は引数でもらった入力値をリストから削り、代わりに
  「追番の集合」と出力値を追加して返す

ソースはこうなった。

```haskell:PoolLayer.hs
type Pix = (Double, Double)

   :

poolMax :: Int -> Image -> [Image]
poolMax s im = [fst pixs, snd pixs] 
  where
    pixs = unzip $ map unzipPix (poolMax' s im)

   :

poolMaxLine :: Int -> [[Double]] -> [Pix]
poolMaxLine _ [] = []
poolMaxLine s ls
  | len == 0  = []
  | otherwise = pixs : poolMaxLine s ls'
  where
    len  = length $ head ls
    pixs = max' $ zip (concatMap (take s) ls) [0.0 ..]
    ls'  = map (drop s) ls

max' :: [Pix] -> Pix
max' [] = error "empty list!"
max' [x] = x
max' (x:xs) = maximum' x (max' xs)

maximum' :: Pix -> Pix -> Pix
maximum' a@(v1, i1) b@(v2, i2) = if v1 < v2 then b else a
```

`Pix`の組の定義で追番が整数でなく`Double`なのは、追番の集合を
「画像」データとして保持するため型を合わせたから。`poolMax`で
組のリストから「出力値」と「追番集合」を分離して返している。
`poolMaxLine`中の

```haskell
    pixs = max' $ zip (concatMap (take s) ls) [0.0 ..]
```

が各画素に追番を付けて最大値を選択しているところだ。

```haskell:Layer.hs
forwardLayer :: Layer -> Image -> [Image]
forwardLayer (NopLayer)         i = [i]
forwardLayer (ActLayer f)       i = [activate f    i, i]
forwardLayer (MaxPoolLayer s)   i =  poolMax  s    i
forwardLayer (ConvLayer s fs)   i = [convolve s fs i, i]
   :
```

`forwardLayer`においてプーリング層だけ他と異なっているのがわかるだろう。
他は全て引数の`Image`(=i)をその層で計算された出力値の後ろにくっつけて
返している。プーリング層ではiをくっつけず`PoolMax`の戻り値をそのまま
使う。これが「入力値を削る」ということだ。

ここまでが順伝播での「準備段階」。これで逆伝播での処理の説明ができる。
その処理は次の通り。

* 誤差と追番を組にする(`depoolMax`内の`concatWith`)
* その組から小領域を生成する(追番のところは誤差値、それ以外は0)(`expand`)

順伝播で頑張った分、逆伝播は単純になった。ソースではこう。

```haskell:PoolLayer.hs
depoolMax :: Int -> Image -> Delta -> (Delta, Layer)
depoolMax s im d = (zipWith (concatWith (expand s 0.0)) im d, MaxPoolLayer s)
  where
    concatWith :: ([Int] -> [Double] -> [[Double]])
               ->  [[Double]] -> [[Double]] -> [[Double]]
    concatWith f i d = concat (zipWith f (map (map truncate) i) d)

expand :: Int -> Double -> [Int] -> [Double] -> [[Double]]
expand s r ps ds = map concat (transpose $ map split' $ zipWith ex ps ds)
  where
    split' = split s
    ex :: Int -> Double -> [Double]
    ex p d = take (s*s) (replicate p r ++ [d] ++ repeat r)

split :: Int -> [a] -> [[a]]
split s [] = []
split s xs
  | length xs < s = [xs]
  | otherwise     = l : split s ls
    where
      (l, ls) = splitAt s xs
```

`concatWith`は少々ややこしいが追番集合を実数から整数に変換して誤差と
組にしたうえで`expand`に渡している。

これで誤差を上層へ伝播できた。

### 2-3. 畳み込み層

#### (1) 誤差の計算


#### (2) 勾配の計算


#### (3) フィルタ更新



## 3. 評価

それでは早速出来上がったプログラムを実行して学習をさせてみよう。
(ソースは[ここ](https://github.com/eijian/deeplearning/tree/version-0.3.0.0))

```shell
$ cabal clean
$ cabal build
  :
$ ./dist/build/train/train
Initializing...
Training the model...
iter =     0/200 accuracy = 0.3333333333 time = 0.13968s
iter =     5/200 accuracy = 0.3333526481 time = 11.021087s
iter =    10/200 accuracy = 0.3333741834 time = 21.513648s
iter =    15/200 accuracy = 0.3334006436 time = 33.707092s
iter =    20/200 accuracy = 0.3334352183 time = 45.034608s
iter =    25/200 accuracy = 0.3334818706 time = 55.7984s
  :
```


### 3-1. 前回分（全結合層のみ）との比較

#### (1) 学習結果(認識精度)

上記のプログラムを10回実行し、それぞれ認識精度と実行時間を計測した。
今回epoch数は200(前回は500)としたが理由は後述する。結果は次のグラフの
とおり。

（グラフ1）

点線が各試行時の実測値、太い実線のうち青が10回の平均だ。点線のうち
2本が明らかに他と違って認識精度がほとんど上がっていない。これは
最初にランダムに設定するフィルタ初期値が良くないからだと思われる。
この2つを入れると平均ががくんと下がってしまうので、ズルをしてこれらを
「異常値」として無視しよう。そうすると太いオレンジ線のようになり
一安心だ。

次にyusugomori実装と比較してみる。

（グラフ2）

（あくまでズルした平均値だが）認識精度がyusugomori実装とほぼ同じに
なった。実は逆伝播処理の「値の正しさ」はきちんと検証していないのだが、
この結果をみるとそんなに外していないのかな？ということでよしとする。
やっとここまできた。

#### (2) 処理時間

ただ、いいことばかりではない。
畳み込み層まで逆伝播したため、学習にかかる時間が増えてしまった。
200 epoch実行時の結果を次表に示す。

（表）

認識精度と処理時間でプロットしてみたのが次のグラフ。

（グラフ3）

このように、処理時間と認識精度を秤にかけると、畳み込み層まで逆伝播させると
得られる精度に対しあまりアドバンテージがないように思える。もちろん、
認識精度を99%以上まで非常に高くする場合は必要なのだろうが。
一方で、当然ながら私の実装のまずさもあるだろう。やたら再帰を使うとか
自分でも頭が混乱するような処理になっているので、もっと簡潔な実装に
改められたら改善するかもしれない。今後の課題の一つだ。

### 3-2. メモリリーク！？

さて、表題に「逆伝播完成？」とクエスチョンを付けた理由がこれだ。
epoch数を200に下げた理由も。

やっとできたと思ってepoch数500で実行してみるとなかなか終わらない。
開始時は1 epochの処理に約2秒かかったので単純計算では1000秒になるが
30分経っても350程度。おかしいと思って`top`コマンドでプロセスを見て
みたらメモリを10GBも食っていたのですぐ停止した！

気を取り直してもう一度実行中の`top`コマンドの出力がこれ。`train`
プロセスが大量のメモリを消費しているのがわかる。これは繰り返し回数が
だいたい180ぐらいのときの状態。

```shell
Processes: 162 total, 3 running, 159 sleeping, 639 threads             00:22:32
Load Avg: 1.99, 1.98, 1.80  CPU usage: 8.48% user, 32.11% sys, 59.40% idle
SharedLibs: 92M resident, 33M data, 6516K linkedit.
MemRegions: 23895 total, 477M resident, 29M private, 103M shared.
PhysMem: 4080M used (1131M wired), 14M unused.
VM: 471G vsize, 623M framework vsize, 71855224(48041) swapins, 73935000(0) swapo
Networks: packets: 631497/460M in, 456172/62M out.
Disks: 2706786/300G read, 1541857/302G written.

PID    COMMAND      %CPU TIME     #TH   #WQ  #PORT MEM    PURG   CMPRS  PGRP
25694  train        81.4 08:49.94 1/1   0    10    1064M- 0B     4044M+ 25694
0      kernel_task  76.5 02:28:47 114/7 0    2     443M-  0B     0B     0
  :
```

Macのメモリ管理についてはよく知らないが、`train`プロセスの使用メモリが
1064M、CMPRSが4044Mで、合わせて5100M=5GBほども消費している。
これはいただけない。

本実装ではやたら（無駄に？）再帰を使ってしまっているが、その効率が
悪いのかもと思いつつ、消費メモリが増える一方なのはやはりヒープ領域を
やたら使っているのだろう。ググると、`foldl'`を使えとかサンクがどうとか
いろいろあるみたいだが、簡単には解決しそうになかったので今回はここまで。
対策は次回に頑張ろうと思う。

## 4. まとめ

今回でやっと一通りCNNが
[実装](https://github.com/eijian/deeplearning/tree/version-0.3.0.0)
できた。学習能力も手本としたyusugomori実装と同等のものができた。
しかしながら、上述のとおりメモリを大量に消費するという問題を抱えたままで、
このままでは全く実用に耐えない。

次回はこの問題を解決させたいと思う（できないかも・・・）。
