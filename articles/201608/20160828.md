# DeepLearning(1): まずは順伝播(下)

さて、今回からは新たなネタとしてDeepLearningに取り組もう。
DeepLearningといえばすでにブームは去って、今は現実の課題に
どんどん活用されている状況だ。使いやすく性能のいいツールや
ライブラリがいろいろあり、ちょっと学べば簡単にその恩恵に
与ることができる（かもしれない）。

しかし個人的には、仕組みがわからないのをただ使うのは面白くないし
個人的に写真の自動分類をしたいというニーズもあるし、遅まきながら
自分で作ってみよう、というわけだ。

## 各層の順伝播処理

`loop`の中で呼び出している`train`が学習の実体だが、中身は各層の
順伝播処理を呼んでいるだけなので簡単だ。

```haskell
(Trainer.hs)

train :: [Layer] -> Trainer -> IO (Image, [Layer])
train [] (i, c) = return (i, [])
train ls (i, c) = do
  let op  = forwardProp ls [i]
      ls' = backwordProp ls op
  return (head op, ls')
```

`forwardProp`が順伝播、`backwordProp`が逆伝播だが、今回は順伝播のみ
実装した。その実体は再帰によりリスト内の層を順に適用している。
さらに、層毎にその独自処理を呼び出すようにした。

```haskell
(Layer.hs)

forwardProp :: [Layer] -> [Image] -> [Image]
forwardProp [] is = is
forwardProp (l:ls) is = forwardProp ls (forward l is)

forward :: Layer -> [Image] -> [Image]
forward _ [] = []
forward NopLayer i = i
forward l@(ActLayer f) im@(i:is)     = (activate l i):im
forward l@(MaxPoolLayer s) im@(i:is) = (poolMax l i):im
forward l@(ConvLayer s fs) im@(i:is) = (convolve s fs i):im
forward l@(HiddenLayer fs) im@(i:is) = (connect fs i):im
forward l@(FlattenLayer f) im@(i:is) = (f i):im
```

以下、各レイヤでの処理を説明する。

### 何もしない層(NopLayer)

これは上記の通り、入力をそのまま返している。プログラムの動作を確認する
ために用意したダミーだ。何も言うことはない。

### 畳み込み層(ConvLayer)

畳み込み層では、画像の各チャネルについてフィルタを適用する。
フィルタの大きさは3×3などの比較的小さいものだ。一般的にどうなのか
わからないが簡便のため正方形だけ扱う。

各チャネルの二次元データ上の各画素について、そこを起点にフィルタと
同じ大きさの正方形を取り出してフィルタの対応する画素と掛け合わせて
合計するのだ。

（図）

この処理、手続き型言語であれば多重ループで難なく書ける処理なのだが、
Haskellでどう書くか。。。画像をリストでなく`Array`で表現して、必要な要素を
直接ポイントすれば同じく多重ループで書けるが、再帰で処理するために
次のようにした。

（図）

フィルタの大きさをnとすると、二次元のデータの最初のn行を`take`で取り出して
各行の処理(`convolveLine`)を行う。そのあと、最初の行を取り除き、
また同じことを繰り返すのだ。処理する行数がフィルタの大きさより小さく
なったら終了する。

```haskell
(ConvLayer.hs)

-- s: filter size

convolvePlain :: Int -> [Double] -> Plain -> Plain
convolvePlain s k ps
  | len < s   = []
  | otherwise = (convolveLine s k p:convolvePlain s k ps')
  where
    len = length ps
    p   = take s ps
    ps' = tail ps
```

各行について`take`で行の最初からn個取り出すとn×n個の画素データが得られる。
これにフィルタを適用する。そのあと、各行の最初の要素を取り除き、それを
使って同じ処理を行が終わるまで繰り返す。`sum $ zipWith (*)`の部分が
フィルタを適用しているところである。

```haskell
(ConvLayer.hs)

convolveLine :: Int -> [Double] -> [[Double]] -> [Double]
convolveLine s k ps
  | len < s   = []
  | otherwise = ((sum $ zipWith (*) vs k):convolveLine s k ps')
  where
    len = minimum $ map (length) ps
    vs = concat $ map (take s) ps
    ps' = map (tail) ps
```

こうすれば、画像の各画素に対して再帰処理でフィルタを適用できる。

その後、入力画像の各チャネルの処理結果を足し合わせる必要がある。
これは各チャネルの同じ位置にある画素データを足すだけなので簡単な
ことのはずだが、頭がこんがらがって以外と手間取った。

```haskell
(ConvLayer.hs)

sumPlains :: Double -> [Plain] -> Plain
sumPlains b [] = repeat $ repeat b  -- 2 Dimensions (X*Y)
sumPlains b (p:ps) = zipWith f p (sumPlains b ps)
  where
    f :: [Double] -> [Double] -> [Double]
    f [] _          = []
    f (a:[]) (b:_) = [a + b]
    f (a:as) (b:bs) = (a + b):(f as bs)
```

特に全チャネル分を足し合わせ、さらにバイアス値を加える必要があるので
多少複雑になってしまった。全画素に同じバイアス値を加えるために、
`repeat $ repeat バイアス値`により画像サイズがわからなくても
処理できた。普通ならちゃんと画像サイズ分の二次元データを用意する
ところだろう。細かいところだが、遅延評価の恩恵か。

### 活性化層/活性化(ActLayer)

先にも書いた通り、ニューラルネットについての書籍やサイトでは活性化層という
独立した層として説明されておらず、畳み込み層や隠れ層の後処理的な扱いだ。
が、今回は独立した層としたほうが「私にとって」わかり易そうだったので
分けることにした。後でチューニングのために他の層に統合するかもしれない・・・。

活性化関数として、まずはReLUとsoftmax関数を用意した。それぞれ下記で表される。
これらはActLayer層の作成時にどちらか選ぶのだ。

(ReLU)
\[f(x) = \max(x, 0)\]

(Softmax)
\[f(x) = \frac{e^{x_i}}{\sum_{k=1}^K e^{x_k}} \]

実装はこう。

```haskell
(ActLayer.hs)

relu :: ActFunc
relu as = map f as
  where
    f :: Double -> Double
    f a = if a > 0.0 then a else 0.0

softmax :: ActFunc
softmax as = map (\x -> x / sume) es
  where
    amax = maximum as
    es   = map (\x -> exp (x - amax)) as
    sume = sum es

activate :: Layer -> Image -> Image
activate (ActLayer f) im = map (map f) im
```

記事を書いていて、ReLUのほうは素直に`maximum`を使えばいいと思った。
後で直そう。Softmaxの方も、ほぼ定義通りだ。ただし入力`x`に対し、
`x`の最大値を引いているがこれは発散しないための工夫だそうだ。
本体である`activate`は画像のすべての画素に対して活性化関数を適用する。
まあ、難しいものではない。

### プーリング層(MaxPoolLayer)

プーリング層としては最大プーリングのみ対応する。他も必要になったら
その時考えよう。


### フラット化(FlattenLayer)

これは層というよりは整形処理のようなものだ。畳み込み層やプーリング層は
二次元平面が複数チャネルという、いわゆる「画像」の形をしているが、
隠れ層では「一次元配列」を入力に取る。ということでそれらの変換が必要なのだ。
その変換関数は画像と同じところに定義している。

```haskell
(Image.hs)

flatten :: Image -> Image
flatten im = [[concat $ concat im]]
```

単に画像の一枚目からが措置を一列に並べているだけである。
ただし、`Layer`として同型の関数で処理するためにはあくまでも
「画像」である必要がある。なのでわざわざ結果を3次元配列にみせかけている。
=の後ろの角括弧2つがそれだ。

### 隠れ層(HiddenLayer)

これはいわゆる全結合層なのだが、他の記事やプログラムを見ると隠れ層と
いう名で作られているのでそれに倣った。隠れ層としながら、最終の出力層も
この`HiddenLayer`を使っているので名前は変えるべきかもしれない。。。

この層では、N個の入力をM個の出力に変換する。Nの要素全てがMの要素全てに
関連付けられているため全結合というらしい。その関連付けをフィルタとして
与える必要がある。初期はランダム値を設定し、学習によってその値を少しずつ
補正することで画像認識などができるらしい。フィルタはN×Mの二次元リストで
与えることにしよう。

```haskell
(HiddenLayer.hs)

initFilterH :: Int -> Int -> IO [FilterH]
initFilterH k c = do
  f <- forM [1..k] $ \i -> do
    f' <- initKernel c
    return f'
  return f
  where
    a = 1.0 / fromIntegral c
    initKernel :: Int -> IO FilterH
    initKernel c = do
      w <- forM [1..c] $ \i -> do
        r <- MT.randomIO :: IO Double
        return ((r * 2.0 - 1.0) * a)
      return (0.0:w)
```

プログラム中ではNがc、Mはkで表している。それぞれチャネルとカーネル。
名づけがおかしいかもしれないが。
各要素は入力用素数Nに対し1/N～-1/Nの間の乱数としている。
ただし、最初の要素はバイアス値で、これは0.0とするらしい。

フィルタの処理は次の通り。入力値にフィルタ値を掛けてすべて足しこむ。
式で書くとこうなる。なおフィルタの要素は $w_{ij}$ としている。


\[M_i = \sum_{j=0} N_j w_{ij} + b_j\]

実装はこう。

```haskell
(HiddenLayer.hs)

connect :: [FilterH] -> Image -> Image
connect [] _ = error "invalid FilterH"
connect _ [] = error "invalid Image"
connect fs [[im]] = [[map (dot im) fs]]
  where
    dot :: [Double] -> [Double] -> Double
    dot im f = sum $ zipWith (*) (1.0:im) f
```

### 層の組み立て

## 実行してみた

以上でひとまず順伝播については実装できた（と思う）。まずコンパイル。

```shell
$ cabal configure
  :
$ cabal build
  :
```

では実行してみよう。

```shell
$ dist/build/deeplearning/deeplearning
Building the model...
Training the model...
iter = 0/200 time = 0s ratio = 0.0
iter = 5/200 time = 0.0030001s ratio = 0.33333713817332733
iter = 10/200 time = 0.333019s ratio = 0.33333713817332733
iter = 15/200 time = 0.682039s ratio = 0.33333713817332733
     :
iter = 200/200 time = 13.0807482s ratio = 0.33333713817332733
Finished!
```

出力内容は、左からエポック（反復回数）、経過時間(秒)、正解率だ。
正解率は、全テストデータについて、出力リストから正解にあたる要素の
値を取り出して平均したもの。先の通り3種類に分類されるデータを
使ったので、何も学習していない状況では出力は均等割合となり約1/3に
なっている。まあ、学習してないからこの結果だけではなんとも言えないが。

## まとめ

今回はCNNの画像認識プログラムの初回として以下に取り組んだ。

* CNNで使われるいろいろな型を定義した。
* 入力値を変換するいろいろな「層」を定義した。
* これらを使って順伝播の処理を実装した。

各層の処理を経て、なんとなく結果が出力されたので雰囲気はつかめたかなと。

順伝播だけでは何にも有用な結果は得られないが、それは次回取り組む（だろう）
逆伝播の結果に期待したい。

しかし今回は文章が長くなってしまった。いろいろ下準備とかmain関数とかの
説明が多かったと反省。次回以降は短くまとめられるだろう。
