# DeepLearning(1): まずは順伝播

さて、今回からは新たなネタとしてDeepLearningに取り組もう。
DeepLearningといえばすでにブームは去って、今は現実の課題に
どんどん活用されている状況だ。使いやすく性能のいいツールや
ライブラリがいろいろあり、ちょっと学べば簡単にその恩恵に
与れる（かもしれない）。

しかし個人的には仕組みがわからないのを使うのも面白くないし
自動的に写真の分類をしたいというニーズもあるし、遅まきながら
自分で作ってみよう、というわけだ。

#### 目標と参考資料

最終的には「一般物体認識」まで行きたい（というかそうでないと
写真の分類にならない）が、目標が高すぎると頓挫するのでこの
記事では以下の2つのステップまでとする。

* ステップ1: yusugomoriさんのpython実装を写経する
* ステップ2: 上を使ってお決まりのMNISTデータを使った性能検証をする

「自分で作ってみよう」と大口を叩いていながら他の方の実装を写経する
とは詐欺的だが、そこはご愛嬌だ。そのyusugomoriさんの実装は下記に
ある。

（URL）

今回作るものは、畳み込みニューラルネットワーク(Convolutional Neural
Network, CNN)による画像認識プログラムとする。以下、参考にした書籍や
Webサイトを列挙する。

*
*
*
*

今回のソースは[こちら]
(https://github.com/eijian/deeplearning/tree/version-0.1.0.0)

#### まずは型を考える

（ちゃんと理解できているとは言い難いが）CNNによる画像認識は
次の図のように「画像」を各レイヤで変換していって最終的に分類結果
（どれに該当するかを確率で示す）を得るようだ。

（図）

そこでまずは「画像(Image)」型と「レイヤ(Layer)」型を定義しよう。
通常のカラー画像だと、XY二次元のドットで構成された平面(Plain)が
赤緑青の3色（チャネル）分集まってできている。画像ファイル
だと各ドットの色の強さは0-255の整数で表すことが多いと思うが、
CNNでは強さを0.0-1.0の実数で表すようだ。

ということで、画像は次のように定義した。実態は`Double`の3次元リストだ。

```haskell(Image.hs)
type Plain = [[Double]]    -- 2D: X x Y pixels
type Image = [Plain]       -- n dimension
```

わざわざ`Image`を`Plain`のリストにしたのは、`Plain`ごとに処理することが
多いからだ。あとついでに、「学習」の際に必要となる教師データも定義しておく。

```haskell(Image.hs)
type Class = [Double]    -- teacher vector
type Trainer = (Image, Class)
```

実数のリストだが、教師データではどれか一つが1.0、他が0.0である情報だ。

次にレイヤを考える。CNNでは次のようなレイヤが使用される。

* 畳み込み層 (convolution layer)
* プーリング層 (pooling layer)
* 活性化層/活性化関数 (activation layer)
* 全結合層 (fully connected layer)

このうち、活性化層というのは一般的な表現かどうかよくわからない。
各種記事では畳み込み層や全結合層の後処理みたいになっていて独立した
層として扱っていないからだ。今回は、実装する上でわかりやすいと
考えたので分けることにした。ただしチューニング段階でやっぱり一つに
まとめるかもしれない・・・。

これらを総称してレイヤ型としたい。最初は型クラスとして`Layer`を
定義し各層を型としてやればいいと考えた。が、後述するが各層をつなげて
一連の変換処理を表現するのに「リスト」を使ったので（私の知識範囲では）
うまい方法が思いつかなかった。ということで、`Layer`型を次のように定義
することにした。

```haskell(LayerType.hs)
data Layer = NopLayer
           | ConvLayer Int [FilterC]
           | MaxPoolLayer Int
           | ActLayer ActFunc
           | HiddenLayer [FilterH]
           | FlattenLayer (Image -> Image)
```

ここで、`NopLayer`は何も変換しないダミーのレイヤ（テスト用）、
プーリング層は実用上Max Poolingだけでよいと考えて`MaxPoolLayer'、
全結合層は隠れ層ということで`HiddenLayer`としている。
（対応付けがわかりにくいが）
各定義中に出てくるよくわからない型はそれぞれ以下のように定義
してある。`ActFunc`は活性化関数、`FilterC`は畳み込み層のための
フィルタ、`FilterH`は全結合層(隠れ層)のためのフィルタだ。

```haskell(LayerType.hs)
-- for Activation Layer
type ActFunc = [Double] -> [Double]

-- filter for Convolution Layer
type Kernel = [[Double]]
type Bias   = Double
type FilterC = (Kernel, Bias)

-- filter for Hidden Layer
type FilterH = [Double]

```

#### 学習用プログラム

deeplearningで画像認識させるためのステップは大雑把には次のような
手順を踏む必要があると思っている。

1. 大量のサンプル画像を用意し、それらを分類する。
2. サンプル画像から「教師データ」を作成する。
3. 教師データを使って「学習」を行う。学習とは実際は幾つかの層で
   使われるフィルタを教師データを元に調整していくこと。
4. 画像を調整済みフィルタを使って分類する（各分類の可能性を計算する）。

1と2はプログラム以前の準備段階だ。が、yusugomoriさんのプログラムでは
教師データと学習状況の確認につかうテストデータをプログラム内で生成
している。最終的には学習データとテストデータは外から与える形にしたいが、
まずは同じようにプログラム内で生成するようにしよう。

##### 教師データの生成

ゆくゆく教師データを外から与えることも考え、「画像データの集合」
（プールとする）の型を作ろう。これらの集合から幾つかを取り出して
学習に使いたい。そこで、データに追番をつけて`Map`に登録
することにした。とりあえずはオンメモリで処理できれば良いので
以下のようにプール（オンメモリ版、`MemPool`）を定義した。

```haskell(Pool.hs)
class Pool p where
  getImages :: p -> Int -> Int -> IO [Trainer]
  nSample :: p -> Int

newtype MemPool = MemPool { m :: Map.Map Int Trainer }
```





