# DeepLearning(3): そして逆伝播（でも全結合層まで）

第1、2回で順伝播の処理は実現した。今回やっと「学習」処理に入る。
（それにしても時間が取れずまたしてもだいぶ間が空いてしまった。記憶が飛んでいる）

前回までで作成したプログラムでは、多段のニューラルネットワークを構成した。
その終盤には2つの全結合層（隠れ層と出力層）が含まれている。本稿では、
逆伝播による学習で全結合層のフィルタ（ウェイト）を更新する部分について
解説し、学習によりフィルタの分類能力が向上することを確認したい。

## 全結合層の逆伝播処理

### 処理の流れ

逆伝播の理論的なところや数式の詳細は各種書籍やWebサイトを見ていただくとして、
今回作成した処理がどのような流れになっているかをざっと表と図にしてみた。

(表）
（図）

誤差($\delta$)が各層で計算され、次の層へ伝わっていくイメージが伝わるだろうか?
実装面では、逆伝播処理を始める前に順伝播で生成された各層の出力のリストと
各層を組(タプル)のリストにして(図の点線)、それを再帰処理している。
再帰の際に計算された誤差を次に引き渡していくのだ。
ただし逆伝播の際計算に使う各層は順伝播のときのものではなく「逆変換」する
ものである。例えば全結合層のフィルタは行列として表されるが、逆伝播時は
それを転置した行列を使うし、活性化関数も元の関数の導関数を使う。
（という理解で合っているよね?）

全結合層のように学習対象のフィルタを持つ層では、誤差だけでなく前の層から
伝わってきた誤差を使ってフィルタの差分も求める($\Delta W$)。

これをすべての層に対して遡っていけば、めでたく（一回の）学習が完了するわけだ。
ただ畳み込み層の逆伝播はちょっと複雑っぽいので次回にし、今回は全結合層だけに
しておく。

### 


## 「学習」の評価

プログラムも出来上がったことだし、どれだけ学習するか評価してみよう。
コンパイルと実行は次の通り。

```shell
% cabal build
   :
% ./dist/build/train/train
Initializing...
Training the model...
iter =     0/500 accuracy = 0.3333333333 time = 0.149965s
iter =     5/500 accuracy = 0.3333413554 time = 5.132365s
   :
```

途中経過を 5 epoch 毎に画面に出している。前回から少しフォーマットを
変更し、正答率を「認識精度=accuracy」に改めている。

### 学習結果（ノーマル版）

上記のプログラムを10回実行し、それぞれ認識精度と実行時間を計測した。
結果は以下のグラフの通り。

（グラフ）

点線が各試行時の実測値、太い実線が10回の平均値だ。これを見ると、認識精度の
向上具合は各試行でかなりばらついているのがわかる。また、認識率の向上が
急峻なものと緩慢なものにかなり差がついている。

プログラムでは、学習用データ、テスト用データ、および各フィルタに乱数を
使っているが、それらの初期状態によりこれだけの差が生じてしまっていると
思われる。（学習効果が薄い=うまく特徴が出ない画像群が生成されたとか、
フィルタの初期状態が行けてないとか）

ただ、総じて 500 epoch ぐらい繰り返せば認識精度が9割を超えることも分かった。
まだ畳み込み層の学習をしていない段階でここまで精度が上がるとは思っておらず、
嬉しい誤算だった。

### 学習結果（学習率の差）

先のグラフで、認識精度の向上は最初からではなく50 epochを超えたあたりから
急に上がりだしている。私は素人なのでよくわからないが、いろいろな情報を見ると
学習率をどう設定するかとか、学習進行に応じて学習率を変化させるとか書かれて
いて、重要なパラメータであることはわかった。

このプログラムでは学習率を0.1に固定しているが、初期段階ではこれが小さすぎる
のかもしれない。ということで、学習率を0.2と0.05に変えて試行した結果も出して
みた。(0.2と0.05の試行は5回、その平均をとった）

（グラフ）

予想通りかというとちょっと微妙だが、学習率を大きくした方がより速く認識精度が
向上していることがわかる。ただ、初っ端から急上昇しているわけではないので
もっと大きくしないといけないのだろう。ただ、大きいままで学習を続けると
収束しないという話もある（？）ので、やはり動的に変化させる手法がいくつか
あるようだ。もっとあとになるがそれにも取り組みたい。

で、今回のプログラムはまずyusugomori実装を「写経」することが第一課題なので
学習率は0.1に戻しておこう。

### yusugomori実装との比較

ここまで、学習が進んだ！と喜んできたわけだが、「写経元」のyusugomori実装と
同じことができているのだろうか？

ということでyusugomori実装との比較をしてみたのが次のグラフだ。

（グラフ）

avg-0.1が本プログラム（学習率0.1、試行10回の平均値、青線）、py-cnnが
yusugomori実装（学習率0.1、試行1回、赤線）、py-cnnfcがyusugomori実装で
畳み込み層の学習を抑制した改造版（学習率0.1、試行1回、緑線）だ。
yusugomori実装では乱数のseedが固定されているため毎回同じ結果になるのと、
後で述べるようにめちゃくちゃ処理時間が掛かるのとで試行は1回だけにした。

先述の通り乱数の生成値により試行結果はかなりぶれるのだが、青と緑の線は
350 epoch近辺からほとんど同じような値になっていて（楽観的に見れば）
本プログラムはyusugomori実装と同等な処理ができているのではないかと思う。
一方本来の学習（=畳み込み層も学習）であれば認識精度が急上昇し、かつ
200 epoch ぐらいでも認識精度が98%を超えてくる。ここまで性能差があると、
早く畳み込み層の学習部分も完成させたいと、モチベーションが上がるものだ。

次に処理時間について見てみる。結果は次の表のとおりである。
(iMac early 2009, 3.0GHz Core 2 Duo, 4GB memory)

|:-:|:-|:-|:-|
||avg-0.1|py-cnn|py-cnnfc|
|処理時間(s/200 epoch)|157|24838|6152|
|処理性能(epoch/s)|1.273|0.008|0.033|
|認識精度(%)|74.2|98.4|62.9|

yusugomori実装の処理時間が半端ではないことがわかると思う。本プログラムも
コンパイルされたネイティブコードであることを考えると決して十分な処理速度
ではないが、それでもまったく比べものになっていない。

NumPyライブラリのインストールに何か抜けている手順があるのだろうか?
インストール時に何か特別なことをした記憶もないので、以下の記事にあるように
「ちゃんとした」インストールができていないのかもしれない。

[Kesin's diary: NumPy, SciPyをちゃんとインストールする](http://kesin.hatenablog.com/entry/20111229/1325174595)

もしくは次の記事のように多重ループと配列要素への直接読み書きが
影響しているのかもしれない。

[numpyで明示的にループを書くと極端に遅くなる](http://qiita.com/nonbiri15/items/ef97b84832055ab807fb)

いずれにせよ、当面Pythonを使う予定はないので深入りはしない...

## まとめ

今回は全結合層部分の逆伝播処理を実装した。これにより学習ができるように
なったので、制度はともかく画像認識ができるようになった。ただ、これはまだ
半分。次回は畳み込み層の逆伝播を実装し、プログラムを完成させようと思う。
