前回簡易版を作ってみたが、縮小した画像が「同一」と見做されなかった。
今回はこれにどう対処するか検討してみる。
各画像を4x4解像度に変換した結果=fingerprintを取った時に、元画像と縮小画像
とで微妙に異なるのが問題だった。簡易版は「fingerprintが全く同じになる」
ことを前提に作ってあったからだ。

そこで、同一画像と見做せるようにする対策案を考えてみた。

A. 解像度をもっと減らす(2x2とか1x1とか)
B. 色階調を減らす(1/256から1/64や1/16とかへ)
C. fingerprintの微妙な違いを許容する

#### A. 解像度をもっと減らす

前回のサンプル画像で調べてみる。2x2に解像度を減らしたところ、2つの画像の
差はなくなった。これは行けるかもと思ったが、別の画像で試したらやはり差が生じた。
また、そもそも2x2程度ではもしかすると異なる画像がたまたま同一のfingerprintに
なる可能性も高まる。この方法は却下だ。

#### B. 色階調を減らす

各色256階調、3原色で1600万色であるから、画像の縮尺が変われば同じ画像でも
多少の差が出てきてしかるべき。であれば、階調を減らせば多少の差は吸収される
のではないか。階調を減らすには256段階(=1byte)の下数桁をマスクして
0にしてやれば良いだろう。つまり、

```
色値 AND 0xFC (0xFCは下2桁を除外するマスク→64段階にする）
```

といった処理をfingerprintの全バイトへ適用するということ。

しかしこの方法は根本解決にならない。色階調を減らしたところで近い色値が「同一」
になる保証はない。極端な例だと、2つの画像のある点で色値がそれぞれ127と128と
なるような場合、どのようなマスクを設定しても「同一」とみなされない。
ゆえにこの方法も却下だ。

#### C. fingerprintの微妙な違いを許容する

もとの発想は、解像度を極端に落とせば、同じ画像ならfingerprintが一致すると
思っていたが微妙に差が出たのであった。となるとその差を無視して「同一」と考える
必要がある。そこで2つの画像の差が閾値以内なら「同一」とみなそう。
当初のアルゴリズムで2段階目に16x16でやろうと考えていたことだ。

ただ当初、最初の段階からやらなかったのは、fingerprintが一致する＝同一画像（の
疑いが強い）とみなせれば`Map`を使ってグループ化でき計算量が抑えられそうだった
からだ。(`Map`を使えば計算量は[tex:O(N\log N)]、しかし微妙な差をチェックする
には総当たりなので計算量は[tex:O(N^2)]に膨らむ。画像数が数千枚になるとかなり
大変な作業になる。）




